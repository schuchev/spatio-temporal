{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c40c8a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "import models\n",
    "import inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "487de150",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Sequence\n",
    "import numpy as np\n",
    "from typing import Union\n",
    "import pandas as pd\n",
    "from typing import Union\n",
    "import torch\n",
    "torch.set_default_dtype(torch.float32)\n",
    "import numpy as np\n",
    "import tensorflow_probability as tfp\n",
    "from typing import Any, Dict, Tuple, List\n",
    "from torch.distributions import Normal\n",
    "tfd = tfp.distributions\n",
    "from scipy.optimize import root_scalar\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Normal\n",
    "import numpy as np\n",
    "from typing import Callable, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea7e409b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seasonality_to_float(seasonality: str, freq: str) -> float:\n",
    "  \"\"\"Convert a valid pandas frequency string to a float, relative `freq`.\n",
    "\n",
    "  Internally, this computes the number of `freq`s in a long period (to\n",
    "  account for leap years), and the number of `seasonality`s, and returns the\n",
    "  ratio.\n",
    "\n",
    "  For example\n",
    "  ```\n",
    "  >>> seasonality_to_float('Y', 'D') == 365.25\n",
    "  >>> seasonality_to_float('Y', 'W') == 52.25\n",
    "  >>> seasonality_to_float('M', 'D') == 30.4375\n",
    "  ```\n",
    "\n",
    "  Args:\n",
    "    seasonality: A valid pandas frequency.\n",
    "    freq: A valid pandas frequency. Should be shorter than `seasonality`.\n",
    "\n",
    "  Returns:\n",
    "    A float of how many `seasonality` periods are in a `freq`, on average.\n",
    "  \"\"\"\n",
    "  four_years = pd.date_range('2020-01-01', periods=5, freq='YS')\n",
    "  y = four_years.to_period(seasonality)\n",
    "  num_seasonality = (y[-1] - y[0]).n\n",
    "\n",
    "  x = pd.date_range(y[0].start_time, y[-1].start_time).to_period(freq)\n",
    "  num_freq = (x[-1] - x[0]).n\n",
    "\n",
    "  return num_freq / num_seasonality\n",
    "\n",
    "\n",
    "def seasonalities_to_array(\n",
    "    seasonalities: Sequence[Union[float,str]],\n",
    "    freq: str\n",
    "    ) -> np.ndarray:\n",
    "  \"\"\"Convert a list of floats or strings to durations relative to a frequency.\n",
    "\n",
    "  Args:\n",
    "    seasonalities: A list of floats or strings representing durations relative\n",
    "      to `freq`. For example, if `freq` is 'D', either 365 or 'Y' would\n",
    "      represent a year. If `freq` is 'M', then either 12 or 'Y' represents a\n",
    "      year.\n",
    "    freq: Frequency of the data.\n",
    "\n",
    "  Raises:\n",
    "    TypeError: If the seasonality is less than or equal to 1.\n",
    "\n",
    "  Returns:\n",
    "    Array of floats greater than 1, representing seasonalities.\n",
    "  \"\"\"\n",
    "  ret = []\n",
    "  for seasonality in seasonalities:\n",
    "    if isinstance(seasonality, str):\n",
    "      seasonality_float = seasonality_to_float(seasonality, freq)\n",
    "      if seasonality_float < 1:\n",
    "        raise TypeError(f'{seasonality=} should represent a time '\n",
    "                        f'span greater than {freq=}, but {seasonality} '\n",
    "                        f'is {seasonality_float:.2f} of a {freq}')\n",
    "\n",
    "    else:\n",
    "      seasonality_float = seasonality\n",
    "      if seasonality_float < 1:\n",
    "        raise TypeError(f'{seasonality_float=} should be larger than 1.')\n",
    "    ret.append(seasonality_float)\n",
    "  return np.array(ret)\n",
    "\n",
    "\n",
    "def _convert_datetime_col(table, time_column, timetype, freq, time_min=None):\n",
    "  \"\"\"Converts a time column in place according to the frequency.\"\"\"\n",
    "  if timetype == 'index':\n",
    "    first_date = pd.to_datetime('2020-01-01').to_period(freq)\n",
    "    table[time_column] = table[time_column].dt.to_period(freq)\n",
    "    table[time_column] = (table[time_column] - first_date).apply(lambda x: x.n)\n",
    "  elif timetype == 'float':\n",
    "    table[time_column] = table[time_column].apply(float)\n",
    "  else:\n",
    "    raise ValueError(f'Unknown timetype: {timetype}')\n",
    "  if time_min is None:\n",
    "    time_min = table[time_column].min()\n",
    "  table[time_column] = table[time_column] - time_min\n",
    "  return table, time_min\n",
    "\n",
    "class SpatiotemporalDataHandler:\n",
    "  \"\"\"Base class for preparing spatiotemporal data.\"\"\"\n",
    "\n",
    "  def __init__(\n",
    "      self,\n",
    "      feature_cols: Sequence[str],\n",
    "      target_col: str,\n",
    "      timetype: str,\n",
    "      freq: str,\n",
    "      standardize: Union[Sequence[str],None] = None,\n",
    "  ):\n",
    "    self.feature_cols = feature_cols\n",
    "    self.target_col = target_col\n",
    "    self.timetype = timetype\n",
    "    self.freq = freq\n",
    "    self.standardize = standardize\n",
    "    self.mu_ = None\n",
    "    self.std_ = None\n",
    "    self.time_min_ = None\n",
    "    self.time_scale_ = None\n",
    "\n",
    "  @property\n",
    "  def _time_idx(self) -> int:\n",
    "    return 0\n",
    "\n",
    "  @property\n",
    "  def _time_column(self) -> str:\n",
    "    return self.feature_cols[self._time_idx]\n",
    "\n",
    "  def get_target(self, table: pd.DataFrame) -> np.ndarray:\n",
    "    table = self._maybe_filter_target_nans(table)\n",
    "    return table[self.target_col].values\n",
    "\n",
    "  def _maybe_filter_target_nans(self, table: pd.DataFrame) -> pd.DataFrame:\n",
    "    if self.target_col in table.columns:\n",
    "      return table[table[self.target_col].notna()]\n",
    "    return table\n",
    "\n",
    "  def copy_and_filter_table(self, table: pd.DataFrame) -> pd.DataFrame:\n",
    "    return self._maybe_filter_target_nans(table.copy())\n",
    "\n",
    "  def get_train(self, table: pd.DataFrame) -> np.ndarray:\n",
    "    \"\"\"Fetch training data.\"\"\"\n",
    "    table = self.copy_and_filter_table(table)\n",
    "    self.mu_ = np.zeros(len(self.feature_cols))\n",
    "    self.std_ = np.ones(len(self.feature_cols))\n",
    "\n",
    "    table, self.time_min_ = _convert_datetime_col(\n",
    "        table, self._time_column, self.timetype, self.freq, None)\n",
    "    features = table[self.feature_cols].values\n",
    "    self.time_scale_ = features[:, self._time_idx].max()\n",
    "\n",
    "    if self.standardize:\n",
    "      if self._time_column in self.standardize:\n",
    "        raise TypeError('Do not standardize the time column!')\n",
    "      idx = [self.feature_cols.index(f) for f in self.standardize]\n",
    "      self.mu_[idx] = np.mean(features[:, idx].astype(float), axis=0)\n",
    "      self.std_[idx] = np.std(features[:, idx].astype(float), axis=0)\n",
    "      features = (features - self.mu_) / self.std_\n",
    "\n",
    "    return features\n",
    "\n",
    "  def get_test(self, table: pd.DataFrame) -> np.ndarray:\n",
    "    \"\"\"Fetch testing data. Call this after `get_train`.\"\"\"\n",
    "    table = table.copy()\n",
    "    table, _ = _convert_datetime_col(\n",
    "        table, self._time_column, self.timetype, self.freq, self.time_min_)\n",
    "\n",
    "    features = table[self.feature_cols].values\n",
    "\n",
    "    if self.standardize:\n",
    "      features = (features - self.mu_) / self.std_\n",
    "\n",
    "    return features\n",
    "\n",
    "  def get_input_scales(self) -> np.ndarray:\n",
    "    input_scales = np.ones(len(self.feature_cols))\n",
    "    input_scales[self._time_idx] = self.time_scale_\n",
    "    return input_scales\n",
    "class BayesianNeuralFieldEstimator:\n",
    "  \"\"\"Base class for BayesNF estimators.\n",
    "\n",
    "  This class should not be initialized directly, but rather one of the three\n",
    "  subclasses that implement different model learning procedures:\n",
    "\n",
    "  - [BayesianNeuralFieldVI](BayesianNeuralFieldVI.md), for\n",
    "    ensembles of surrogate posteriors from variational inference.\n",
    "\n",
    "  - [BayesianNeuralFieldMAP](BayesianNeuralFieldMAP.md), for\n",
    "    stochastic ensembles of maximum-a-posteriori estimates.\n",
    "\n",
    "  - [BayesianNeuralFieldMLE](BayesianNeuralFieldMLE.md), for\n",
    "    stochastic ensembles of maximum likelihood estimates.\n",
    "\n",
    "  All three classes share the same `__init__` method described below.\n",
    "  \"\"\"\n",
    "\n",
    "  _ensemble_dims: int\n",
    "  _prior_weight: float = 1.0\n",
    "  _scale_epochs_by_batch_size: bool = False\n",
    "\n",
    "  def __init__(\n",
    "      self,\n",
    "      *,\n",
    "      feature_cols: Sequence[str],\n",
    "      target_col: str,\n",
    "      seasonality_periods: Union[Sequence[Union[float,str]],None] = None,\n",
    "      num_seasonal_harmonics: Union[Sequence[int],None] = None,\n",
    "      fourier_degrees: Union[Sequence[float],None] = None,\n",
    "      interactions: Union[Sequence[tuple[int, int]],None] = None,\n",
    "      freq: Union[str,None] = None,\n",
    "      timetype: str = 'index',\n",
    "      depth: int = 2,\n",
    "      width: int = 512,\n",
    "      observation_model: str = 'NORMAL',\n",
    "      standardize: Union[Sequence[str],None] = None,\n",
    "      ):\n",
    "    \"\"\"Shared initialization for subclasses of BayesianNeuralFieldEstimator.\n",
    "\n",
    "    Args:\n",
    "      feature_cols: Names of columns to use as features in the training data\n",
    "        frame. The first entry denotes the name of the time variable, the\n",
    "        remaining entries (if any) denote names of the spatial features.\n",
    "      target_col: Name of the target column representing the spatial field.\n",
    "      seasonality_periods: A list of numbers representing the seasonal\n",
    "        frequencies of the data in the time domain. If timetype == 'index', then\n",
    "        it is possible to specify numeric frequencies by using string short\n",
    "        hands such as 'W', 'D', etc., which correspond to a valid Pandas\n",
    "        frequency. See Pandas [Offset\n",
    "        Aliases](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases)\n",
    "        for valid string values.\n",
    "      num_seasonal_harmonics: A list of seasonal harmonics, one for each entry\n",
    "        in `seasonality_periods`. The number of seasonal harmonics (h) for a\n",
    "        given seasonal period `p` must satisfy `h < p//2`. It is an error fir\n",
    "        `len(num_seasonal_harmonics) != len(seasonality_periods)`. Should be\n",
    "        used only if `timetype == 'index'`.\n",
    "      fourier_degrees: A list of integer degrees for the Fourier features of the\n",
    "        inputs. If given, must have the same length as `feature_cols`.\n",
    "      interactions: A list of tuples of column indexes for the first-order\n",
    "        interactions. For example `[(0,1), (1,2)]` creates two interaction\n",
    "        features  - `feature_cols[0] * feature_cols[1]` - `feature_cols[1] *\n",
    "        feature_cols[2]`\n",
    "      freq: A frequency string for the sampling rate at which the data is\n",
    "        collected. See the Pandas [Offset\n",
    "        Aliases](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases)\n",
    "        for valid values. Should be used if and only if `timetype == 'index'`.\n",
    "      timetype: Either `index` or `float`. If `index`, then the time column must\n",
    "        be a `datetime` type and `freq` must be given. Otherwise, if `float`,\n",
    "        then the time column must be `float`.\n",
    "      depth: The number of hidden layers in the BayesNF architecture.\n",
    "      width: The number of hidden units in each layer.\n",
    "      observation_model: The aleatoric noise model for the observed data. The\n",
    "        options are `NORMAL` (Gaussian noise), `NB` (negative binomial noise),\n",
    "        or `ZNB` (zero-inflated negative binomial noise).\n",
    "      standardize: List of columns that should be standardized. It is highly\n",
    "        recommended to standardize `feature_cols[1:]`. It is an error if\n",
    "        `features_cols[0]` (the time variable) is in `standardize`.\n",
    "    \"\"\"\n",
    "    self.num_seasonal_harmonics = num_seasonal_harmonics\n",
    "    self.seasonality_periods = seasonality_periods\n",
    "    self.observation_model = observation_model\n",
    "    self.depth = depth\n",
    "    self.width = width\n",
    "    self.feature_cols = feature_cols\n",
    "    self.target_col = target_col\n",
    "    self.timetype = timetype\n",
    "    self.freq = freq\n",
    "    self.fourier_degrees = fourier_degrees\n",
    "    self.standardize = standardize\n",
    "    self.interactions = interactions\n",
    "\n",
    "    self.losses_ = None\n",
    "    self.params_ = None\n",
    "    self.data_handler = SpatiotemporalDataHandler(\n",
    "        self.feature_cols,\n",
    "        self.target_col,\n",
    "        self.timetype,\n",
    "        self.freq,\n",
    "        standardize=self.standardize)\n",
    "\n",
    "  def _get_fourier_degrees(self, batch_shape: tuple[int, ...]) -> np.ndarray:\n",
    "    \"\"\"Set default fourier degrees, or verify shape is correct.\"\"\"\n",
    "    if self.fourier_degrees is None:\n",
    "      fourier_degrees = np.full(batch_shape[-1], 5, dtype=int)\n",
    "    else:\n",
    "      fourier_degrees = np.atleast_1d(self.fourier_degrees).astype(int)\n",
    "      if fourier_degrees.shape[-1] != batch_shape[-1]:\n",
    "        raise ValueError(\n",
    "            'The length of fourier_degrees ({}) must match the '\n",
    "            'input dimension dimension ({}).'.format(\n",
    "                fourier_degrees.shape[-1], batch_shape[-1]\n",
    "            )\n",
    "        )\n",
    "    return fourier_degrees\n",
    "\n",
    "  def _get_interactions(self) -> np.ndarray:\n",
    "    \"\"\"Set default fourier degrees, or verify shape is correct.\"\"\"\n",
    "    if self.interactions is None:\n",
    "      interactions = np.zeros((0, 2), dtype=int)\n",
    "    else:\n",
    "      interactions = np.array(self.interactions).astype(int)\n",
    "      if np.ndim(interactions) != 2 or interactions.shape[-1] != 2:\n",
    "        raise ValueError(\n",
    "            'The argument for `interactions` should be a 2-d array of integers '\n",
    "            'of shape (N, 2), indicating the column indices to interact (the '\n",
    "            f' passed shape was {interactions.shape})')\n",
    "    return interactions\n",
    "\n",
    "  def _get_seasonality_periods(self):\n",
    "    \"\"\"Return array of seasonal periods.\"\"\"\n",
    "    if (\n",
    "        (self.timetype == 'index' and self.freq is None) or\n",
    "        (self.timetype == 'float' and self.freq is not None)):\n",
    "      raise ValueError(f'Invalid {self.freq=} with {self.timetype=}.')\n",
    "    if self.seasonality_periods is None:\n",
    "      return np.zeros(0)\n",
    "    if self.timetype == 'index':\n",
    "      return seasonalities_to_array(self.seasonality_periods, self.freq)\n",
    "    if self.timetype == 'float':\n",
    "      return np.asarray(self.seasonality_periods, dtype=float)\n",
    "    assert False, f'Impossible {self.timetype=}.'\n",
    "\n",
    "  def _get_num_seasonal_harmonics(self):\n",
    "    \"\"\"Return array of seasonal harmonics per seasonal period.\"\"\"\n",
    "    if self.timetype == 'index':\n",
    "      return (\n",
    "          np.array(self.num_seasonal_harmonics)\n",
    "          if self.num_seasonal_harmonics is not None else\n",
    "          np.zeros(0))\n",
    "    if self.timetype == 'float':\n",
    "      if self.num_seasonal_harmonics is not None:\n",
    "        raise ValueError(\n",
    "            f'Cannot use num_seasonal_harmonics with {self.timetype=}.'\n",
    "        )\n",
    "      # HACK: models.make_seasonal_frequencies assumes the data is discrete\n",
    "      # time where each harmonic h is between 1, ..., p/2 and the harmonic\n",
    "      # factors are np.arange(1, h + 1). Since our goal with continuous\n",
    "      # time data is exactly 1 harmonic per seasonal factor, any h between\n",
    "      # 0 and min(0.5, p/2) will work, as np.arange(1, 1+h) = [1]\n",
    "      return np.fmin(.5, self._get_seasonality_periods() / 2)\n",
    "    assert False, f'Impossible {self.timetype=}.'\n",
    "\n",
    "  def _model_args(self, batch_shape):\n",
    "    return {\n",
    "        'depth': self.depth,\n",
    "        'input_scales': self.data_handler.get_input_scales(),\n",
    "        'num_seasonal_harmonics': self._get_num_seasonal_harmonics(),\n",
    "        'seasonality_periods': self._get_seasonality_periods(),\n",
    "        'width': self.width,\n",
    "        'init_x': batch_shape,\n",
    "        'fourier_degrees': self._get_fourier_degrees(batch_shape),\n",
    "        'interactions': self._get_interactions(),\n",
    "    }\n",
    "\n",
    "  def predict(self, table, quantiles=(0.5,), approximate_quantiles=False):\n",
    "    \"\"\"Make predictions of the target column at new times.\n",
    "\n",
    "    Args:\n",
    "      table (pandas.DataFrame):\n",
    "        Field locations at which to make new predictions. Same as `table` in\n",
    "        [`fit`](), except that `self.target_col` need not be in `table`.\n",
    "\n",
    "      quantiles (Sequence[float]):\n",
    "        The list of quantiles to compute.\n",
    "\n",
    "      approximate_quantiles (bool):\n",
    "        If `False,` uses Chandrupatla root finding to compute quantiles.\n",
    "        If `True`, uses a heuristic approximation of the quantiles.\n",
    "\n",
    "    Returns:\n",
    "      means (np.ndarray):\n",
    "        The predicted means from each particle in the learned ensemble.\n",
    "        The shape is `(num_devices, ensemble_size // num_devices, len(table))`\n",
    "        and can be flattened to a 2D array using `np.row_stack(means)`.\n",
    "        Related https://github.com/google/bayesnf/issues/17\n",
    "\n",
    "      quantiles (List[np.ndarray]):\n",
    "        A list of numpy arrays, one per requested quantile.\n",
    "        The length of each array in the list is `len(table)`.\n",
    "\n",
    "    \"\"\"\n",
    "    test_data = self.data_handler.get_test(table)\n",
    "    \n",
    "    return inference.predict_bnf(\n",
    "        torch.tensor(test_data,dtype=torch.float32),\n",
    "        self.observation_model,\n",
    "        params=self.params_,\n",
    "        model_args=self._model_args(test_data.shape),\n",
    "        quantiles=quantiles,\n",
    "        ensemble_dims=self._ensemble_dims,\n",
    "        approximate_quantiles=approximate_quantiles,\n",
    "    )\n",
    "\n",
    "  def fit(self, table, seed):\n",
    "    \"\"\"Run inference given a training data `table` and `seed`.\n",
    "\n",
    "    Cannot be directly called on `BayesianNeuralFieldEstimator`.\n",
    "\n",
    "    Args:\n",
    "      table (pandas.DataFrame):\n",
    "        A pandas DataFrame representing the\n",
    "        training data. It has the following requirements:\n",
    "\n",
    "        - The columns of `table` should contain all `self.feature_cols`\n",
    "          and the `self.target_col`.\n",
    "\n",
    "        - The type of the \"time\" column (i.e., `self.feature_cols[0]`)\n",
    "          should be `datetime`. To ensure this requirement holds, see\n",
    "          [`pandas.to_datetime`](\n",
    "          https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html).\n",
    "          The types of the remaining feature columns should be numeric.\n",
    "\n",
    "      seed (jax.random.PRNGKey): The jax random key.\n",
    "    \"\"\"\n",
    "    raise NotImplementedError('Should be implemented by subclass')\n",
    "\n",
    "  def likelihood_model(self, table: pd.DataFrame) -> torch.distributions:\n",
    "    \"\"\"Access the predictive distribution over new field values in `table`.\n",
    "\n",
    "    NOTE: Must be called after [`fit`]().\n",
    "\n",
    "    Args:\n",
    "      table (pandas.DataFrame):\n",
    "        Field locations at which to make new predictions. Same as `table` in\n",
    "        [`fit`](), except that `self.target_col` need not be in `table`.\n",
    "\n",
    "    Returns:\n",
    "      A probability distribution representing the predictive distribution\n",
    "        over `self.target_col` at the new field values in `table`.\n",
    "        See [tfp.distributions.Distribution](\n",
    "        https://www.tensorflow.org/probability/api_docs/python/tfp/distributions/Distribution)\n",
    "        for the methods associated with this object.\n",
    "    \"\"\"\n",
    "    test_data = self.data_handler.get_test(table)\n",
    "    \n",
    "    mlp, mlp_template = inference.make_model(**self._model_args(test_data.shape))\n",
    "    \n",
    "    params = self.params_._replace(**{\n",
    "        self.params_._fields[i]: self.params_[i][..., jnp.newaxis]  \n",
    "        for i in range(3)\n",
    "    })\n",
    "\n",
    "    return models.make_likelihood_model(\n",
    "        params,\n",
    "        jnp.array(test_data),\n",
    "        mlp,\n",
    "        mlp_template,\n",
    "        self.observation_model\n",
    "    )\n",
    "\n",
    "\n",
    "class BayesianNeuralFieldMAP(BayesianNeuralFieldEstimator):\n",
    "  \"\"\"Fits models using stochastic ensembles of maximum-a-posteriori estimates.\n",
    "\n",
    "  Implementation of\n",
    "  [BayesianNeuralFieldEstimator](BayesianNeuralFieldEstimator.md).\n",
    "  \"\"\"\n",
    "\n",
    "  _ensemble_dims = 2\n",
    "\n",
    "  def fit(\n",
    "      self,\n",
    "      table,\n",
    "      seed,\n",
    "      ensemble_size=4,\n",
    "      learning_rate=0.005,\n",
    "      num_epochs=50,\n",
    "      batch_size=None,\n",
    "      num_splits=1,\n",
    "      ) -> BayesianNeuralFieldEstimator:\n",
    "    \"\"\"Run inference using stochastic MAP ensembles.\n",
    "\n",
    "    Args:\n",
    "      table (pandas.DataFrame):\n",
    "        See documentation of\n",
    "        [`table`][bayesnf.spatiotemporal.BayesianNeuralFieldEstimator.fit]\n",
    "        in the base class.\n",
    "\n",
    "      seed (jax.random.PRNGKey): The jax random key.\n",
    "\n",
    "      ensemble_size (int): Number of particles in the ensemble. It currently\n",
    "        an error if `ensemble_size < jax.device_count`, but will be fixed\n",
    "        in https://github.com/google/bayesnf/issues/28.\n",
    "\n",
    "\n",
    "      learning_rate (float): Learning rate for SGD.\n",
    "\n",
    "      num_epochs (int): Number of full epochs through the training data.\n",
    "\n",
    "      batch_size (None | int): Batch size for SGD. Default is `None`,\n",
    "        meaning full-batch. Each epoch will perform `len(table) // batch_size`\n",
    "        SGD updates.\n",
    "\n",
    "      num_splits (int): Number of splits over the data to run training.\n",
    "        Defaults to 1, meaning there are no splits.\n",
    "\n",
    "    Returns:\n",
    "      Instance of `self`.\n",
    "    \"\"\"\n",
    "    train_data = self.data_handler.get_train(table)\n",
    "    train_target = self.data_handler.get_target(table)\n",
    "    if batch_size is None:\n",
    "      batch_size = train_data.shape[0]\n",
    "    if self._scale_epochs_by_batch_size:\n",
    "      num_epochs = num_epochs * (train_data.shape[0] // batch_size)\n",
    "    model_args = self._model_args((batch_size, train_data.shape[-1]))\n",
    "    self.params_, self.losses_ = inference.fit_map(\n",
    "        torch.tensor(train_data, dtype=torch.float32),\n",
    "        torch.tensor(train_target,dtype=torch.float32),\n",
    "        seed=seed,\n",
    "        observation_model=self.observation_model,\n",
    "        model_args=model_args,\n",
    "        num_particles=ensemble_size,\n",
    "        learning_rate=learning_rate,\n",
    "        num_epochs=num_epochs,\n",
    "        prior_weight=self._prior_weight,\n",
    "        batch_size=batch_size,\n",
    "        num_splits=num_splits)\n",
    "    return self\n",
    "\n",
    "class BayesianNeuralFieldVI(BayesianNeuralFieldEstimator):\n",
    "  \"\"\"Fits models using stochastic ensembles of surrogate posteriors from VI.\n",
    "\n",
    "  Implementation of\n",
    "  [BayesianNeuralFieldEstimator](BayesianNeuralFieldEstimator.md) using\n",
    "  variational inference (VI).\n",
    "  \"\"\"\n",
    "\n",
    "  _ensemble_dims = 3\n",
    "  _scale_epochs_by_batch_size = True\n",
    "\n",
    "  def fit(\n",
    "      self,\n",
    "      table,\n",
    "      seed,\n",
    "      ensemble_size=16,\n",
    "      learning_rate=0.01,\n",
    "      num_epochs=1_000,\n",
    "      sample_size_posterior=30,\n",
    "      sample_size_divergence=5,\n",
    "      kl_weight=0.1,\n",
    "      batch_size=None,\n",
    "      ) -> BayesianNeuralFieldEstimator:\n",
    "    \"\"\"Run inference using stochastic variational inference ensembles.\n",
    "\n",
    "    Args:\n",
    "      table (pandas.DataFrame):\n",
    "        See documentation of\n",
    "        [`table`][bayesnf.spatiotemporal.BayesianNeuralFieldEstimator.fit]\n",
    "        in the base class.\n",
    "\n",
    "      seed (jax.random.PRNGKey): The jax random key.\n",
    "\n",
    "      ensemble_size (int): Number of particles (i.e., surrogate posteriors)\n",
    "        in the ensemble, **per device**. The available devices can be found\n",
    "        via `jax.devices()`.\n",
    "\n",
    "      learning_rate (float): Learning rate for SGD.\n",
    "\n",
    "      num_epochs (int): Number of full epochs through the training data.\n",
    "\n",
    "      sample_size_posterior (int): Number of samples of \"posterior\" model\n",
    "        parameters draw from each surrogate posterior when making\n",
    "        predictions.\n",
    "\n",
    "      sample_size_divergence (int): number of Monte Carlo samples to use in\n",
    "        estimating the variational divergence. Larger values may stabilize\n",
    "        the optimization, but at higher cost per step in time and memory.\n",
    "        See [`tfp.vi.fit_surrogate_posterior_stateless`](\n",
    "        https://www.tensorflow.org/probability/api_docs/python/tfp/vi/fit_surrogate_posterior_stateless)\n",
    "        for further details.\n",
    "\n",
    "      kl_weight (float): Weighting of the KL divergence term in VI. The\n",
    "        goal is to find a surrogate posterior `q(z)` that maximizes a\n",
    "        version of the ELBO with the `KL(surrogate posterior || prior)`\n",
    "        term scaled by `kl_weight`\n",
    "\n",
    "            E_z~q [log p(x|z)] - kl_weight * KL(q || p)\n",
    "\n",
    "        Reference\n",
    "        > Weight Uncertainty in Neural Network\n",
    "        > Charles Blundell, Julien Cornebise, Koray Kavukcuoglu, Daan Wierstra.\n",
    "        > Proceedings of the 32nd International Conference on Machine Learning.\n",
    "        > PMLR 37:1613-1622, 2015.\n",
    "        > <https://proceedings.mlr.press/v37/blundell15>\n",
    "\n",
    "      batch_size (None | int): If specified, the log probability in each\n",
    "        step of variational inference  is computed on a batch of this size.\n",
    "        Default is `None`, meaning full-batch.\n",
    "\n",
    "    Returns:\n",
    "      Instance of self.\n",
    "    \"\"\"\n",
    "    train_data = self.data_handler.get_train(table)\n",
    "    train_target = self.data_handler.get_target(table)\n",
    "    if batch_size is None:\n",
    "      batch_size = train_data.shape[0]\n",
    "    if self._scale_epochs_by_batch_size:\n",
    "      num_epochs = num_epochs * (train_data.shape[0] // batch_size)\n",
    "    model_args = self._model_args((batch_size, train_data.shape[-1]))\n",
    "    _, self.losses_, self.params_ = inference.fit_vi(\n",
    "        train_data,\n",
    "        train_target,\n",
    "        seed=seed,\n",
    "        observation_model=self.observation_model,\n",
    "        model_args=model_args,\n",
    "        ensemble_size=ensemble_size,\n",
    "        learning_rate=learning_rate,\n",
    "        num_epochs=num_epochs,\n",
    "        sample_size_posterior=sample_size_posterior,\n",
    "        sample_size_divergence=sample_size_divergence,\n",
    "        kl_weight=kl_weight,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "    return self"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Updated)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
